#!/usr/bin/env python3
"""
Demonstration of Robust Research Execution Engine
================================================

This script demonstrates the comprehensive robustness and reliability features
of the AI Scientist v2 system's robust execution engine.

Features demonstrated:
- Error handling and recovery mechanisms
- Circuit breakers and fault tolerance
- Resource monitoring and health checks
- Checkpoint and backup systems
- Self-healing capabilities
- Comprehensive logging and metrics

Author: AI Scientist v2 Autonomous System - Terragon Labs
License: MIT
"""

import asyncio
import logging
import json
import time
from pathlib import Path
from datetime import datetime
import sys
import os

# Add current directory to path for imports
sys.path.insert(0, str(Path(__file__).parent))

try:
    from robust_research_execution_engine import (
        RobustResearchExecutionEngine, 
        RobustConfig, 
        ResearchConfig,
        SystemState,
        CheckpointType
    )
    ROBUST_ENGINE_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Could not import robust execution engine: {e}")
    ROBUST_ENGINE_AVAILABLE = False


def setup_demo_logging():
    """Setup logging for the demonstration."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('demo_robust_execution.log')
        ]
    )


async def demo_basic_robust_execution():
    """Demonstrate basic robust execution with all features enabled."""
    print("\n" + "="*80)
    print("üöÄ DEMO 1: Basic Robust Execution")
    print("="*80)
    
    # Create configuration
    research_config = ResearchConfig(
        research_topic="Robust Neural Network Training with Fault Tolerance",
        output_dir="demo_robust_output_basic",
        max_experiments=3
    )
    
    robust_config = RobustConfig(
        research_config=research_config,
        max_retries=2,
        circuit_breaker_enabled=True,
        checkpoint_enabled=True,
        backup_enabled=True,
        stage_timeout_minutes=5.0,
        max_cpu_percent=75.0,
        max_memory_gb=4.0,
        health_check_interval_seconds=10.0,
        metrics_collection_interval_seconds=5.0,
        log_level="INFO"
    )
    
    # Create execution engine
    engine = RobustResearchExecutionEngine(robust_config)
    
    try:
        print("üîÑ Starting robust research pipeline...")
        start_time = time.time()
        
        # Execute the pipeline
        results = await engine.execute_research_pipeline()
        
        execution_time = time.time() - start_time
        
        # Display results
        print(f"\n‚úÖ Execution completed in {execution_time:.2f} seconds")
        print(f"Status: {results['status']}")
        print(f"Execution ID: {results['execution_id']}")
        print(f"Stages completed: {len(results.get('stages', {}))}")
        
        # Show stage results
        for stage_name, stage_data in results.get('stages', {}).items():
            status = stage_data.get('status', 'unknown')
            print(f"  - {stage_name.title()}: {status}")
        
        # Show system metrics
        system_metrics = results.get('system_metrics', {})
        if system_metrics:
            health_status = system_metrics.get('health_status', {})
            resource_usage = system_metrics.get('resource_usage', {})
            
            print(f"\nüìä System Metrics:")
            print(f"  Health Score: {health_status.get('overall_health_score', 'N/A')}/100")
            print(f"  System State: {health_status.get('system_state', 'Unknown')}")
            
            if resource_usage:
                print(f"  CPU Usage: {resource_usage.get('cpu_percent', 'N/A')}%")
                print(f"  Memory Usage: {resource_usage.get('memory_percent', 'N/A')}%")
        
        # Show error and recovery information
        errors = results.get('errors', [])
        recoveries = results.get('recovery_info', [])
        
        if errors:
            print(f"\n‚ö†Ô∏è  Errors Handled: {len(errors)}")
            for error in errors:
                print(f"  - {error['stage']}: {error['error_type']}")
        
        if recoveries:
            print(f"\nüîß Recovery Operations: {len(recoveries)}")
            for recovery in recoveries:
                print(f"  - Method: {recovery['recovery_method']}, Success: {recovery['success']}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        return None


async def demo_error_handling_and_recovery():
    """Demonstrate error handling and recovery mechanisms."""
    print("\n" + "="*80)
    print("üõ°Ô∏è DEMO 2: Error Handling and Recovery")
    print("="*80)
    
    # Create a configuration that will trigger some errors
    research_config = ResearchConfig(
        research_topic="Testing Error Recovery in Distributed Systems",
        output_dir="demo_robust_output_errors",
        max_experiments=2
    )
    
    robust_config = RobustConfig(
        research_config=research_config,
        max_retries=3,  # More retries to test recovery
        circuit_breaker_enabled=True,
        checkpoint_enabled=True,
        backup_enabled=True,
        stage_timeout_minutes=2.0,  # Shorter timeout to test timeout handling
        max_cpu_percent=50.0,  # Lower limits to test resource monitoring
        max_memory_gb=2.0,
        log_level="DEBUG"
    )
    
    engine = RobustResearchExecutionEngine(robust_config)
    
    # Inject a custom error handler for demonstration
    original_ideation = engine._execute_ideation_stage
    
    async def error_prone_ideation():
        """Ideation stage that fails first few attempts."""
        if not hasattr(error_prone_ideation, 'attempts'):
            error_prone_ideation.attempts = 0
        
        error_prone_ideation.attempts += 1
        
        if error_prone_ideation.attempts <= 2:
            if error_prone_ideation.attempts == 1:
                raise ConnectionError("Simulated API connection failure")
            else:
                raise TimeoutError("Simulated API timeout")
        
        # Succeed on third attempt
        return await original_ideation()
    
    engine._execute_ideation_stage = error_prone_ideation
    
    try:
        print("üîÑ Starting execution with simulated errors...")
        results = await engine.execute_research_pipeline()
        
        print(f"\n‚úÖ Execution completed despite errors!")
        print(f"Status: {results['status']}")
        
        # Show detailed error and recovery information
        errors = results.get('errors', [])
        recoveries = results.get('recovery_info', [])
        
        print(f"\nüìã Error Handling Summary:")
        print(f"  Total Errors: {len(errors)}")
        print(f"  Recovery Operations: {len(recoveries)}")
        print(f"  Final Status: {results['status']}")
        
        for i, error in enumerate(errors, 1):
            print(f"  Error {i}: {error['error_type']} in {error['stage']}")
        
        for i, recovery in enumerate(recoveries, 1):
            print(f"  Recovery {i}: {recovery['recovery_method']} ({'Success' if recovery['success'] else 'Failed'})")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Error demo failed: {e}")
        return None


async def demo_resource_monitoring():
    """Demonstrate resource monitoring and health checks."""
    print("\n" + "="*80)
    print("üìä DEMO 3: Resource Monitoring and Health Checks")
    print("="*80)
    
    research_config = ResearchConfig(
        research_topic="Resource-Intensive Machine Learning Workload",
        output_dir="demo_robust_output_monitoring",
        max_experiments=4
    )
    
    robust_config = RobustConfig(
        research_config=research_config,
        health_check_interval_seconds=5.0,
        metrics_collection_interval_seconds=2.0,
        max_cpu_percent=60.0,
        max_memory_gb=3.0,
        log_level="INFO"
    )
    
    engine = RobustResearchExecutionEngine(robust_config)
    
    try:
        print("üîÑ Starting execution with resource monitoring...")
        
        # Start execution
        execution_task = asyncio.create_task(engine.execute_research_pipeline())
        
        # Monitor execution in parallel
        monitoring_task = asyncio.create_task(monitor_execution_progress(engine))
        
        # Wait for both tasks
        results, _ = await asyncio.gather(execution_task, monitoring_task, return_exceptions=True)
        
        if isinstance(results, Exception):
            print(f"‚ùå Execution failed: {results}")
            return None
        
        print(f"\n‚úÖ Execution completed with monitoring!")
        
        # Show final system metrics
        system_metrics = results.get('system_metrics', {})
        resource_alerts = system_metrics.get('resource_alerts', [])
        
        print(f"\nüìä Monitoring Summary:")
        print(f"  Resource Alerts: {len(resource_alerts)}")
        print(f"  Health Checks Performed: Multiple during execution")
        
        if resource_alerts:
            print(f"\n‚ö†Ô∏è  Resource Alerts:")
            for alert in resource_alerts[-5:]:  # Show last 5 alerts
                alert_time = datetime.fromtimestamp(alert['timestamp']).strftime("%H:%M:%S")
                print(f"  - {alert_time}: {alert['type']} - {alert['value']:.1f} (limit: {alert['limit']})")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Monitoring demo failed: {e}")
        return None


async def monitor_execution_progress(engine):
    """Monitor execution progress in real-time."""
    print("\nüîç Starting real-time monitoring...")
    
    last_stage = ""
    monitoring_start = time.time()
    
    while True:
        try:
            status = engine.get_execution_status()
            current_stage = status.get('current_stage', '')
            execution_time = status.get('execution_time_seconds', 0)
            
            # Print stage changes
            if current_stage != last_stage and current_stage:
                print(f"  üîÑ Stage: {current_stage.title()} (t+{execution_time:.1f}s)")
                last_stage = current_stage
            
            # Print system state changes
            system_state = status.get('system_state', 'unknown')
            if system_state in ['degraded', 'critical']:
                print(f"  ‚ö†Ô∏è  System state: {system_state}")
            
            # Check if execution is complete
            if not current_stage or system_state == 'shutdown':
                break
            
            # Prevent infinite monitoring
            if time.time() - monitoring_start > 300:  # 5 minutes max
                print("  ‚è∞ Monitoring timeout reached")
                break
            
            await asyncio.sleep(3)
            
        except Exception as e:
            print(f"  ‚ùå Monitoring error: {e}")
            break
    
    print("  ‚úÖ Monitoring completed")


async def demo_checkpoint_and_backup():
    """Demonstrate checkpoint and backup functionality."""
    print("\n" + "="*80)
    print("üíæ DEMO 4: Checkpoint and Backup Systems")
    print("="*80)
    
    research_config = ResearchConfig(
        research_topic="Checkpointed Distributed Training Systems",
        output_dir="demo_robust_output_checkpoints",
        max_experiments=2
    )
    
    robust_config = RobustConfig(
        research_config=research_config,
        checkpoint_enabled=True,
        backup_enabled=True,
        log_level="INFO"
    )
    
    engine = RobustResearchExecutionEngine(robust_config)
    
    try:
        print("üîÑ Starting execution with checkpointing...")
        results = await engine.execute_research_pipeline()
        
        print(f"\n‚úÖ Execution completed!")
        
        # Show checkpoint information
        checkpoints = engine.checkpoint_manager.list_checkpoints()
        backups = engine.backup_manager.list_backups()
        
        print(f"\nüíæ Checkpoint and Backup Summary:")
        print(f"  Checkpoints Created: {len(checkpoints)}")
        print(f"  Backups Created: {len(backups)}")
        
        if checkpoints:
            print(f"\nüìã Checkpoints:")
            for cp in checkpoints[:5]:  # Show first 5
                cp_time = datetime.fromtimestamp(cp.timestamp).strftime("%H:%M:%S")
                print(f"  - {cp_time}: {cp.checkpoint_type.value} ({cp.stage})")
        
        if backups:
            print(f"\nüíº Backups:")
            for backup in backups[:3]:  # Show first 3
                backup_time = datetime.fromisoformat(backup['datetime']).strftime("%H:%M:%S")
                size_kb = backup['file_size'] / 1024
                print(f"  - {backup_time}: {backup['backup_name']} ({size_kb:.1f} KB)")
        
        # Demonstrate checkpoint restoration
        if checkpoints:
            print(f"\nüîÑ Testing checkpoint restoration...")
            latest_checkpoint = checkpoints[0]
            restored_data = engine.checkpoint_manager.restore_checkpoint(latest_checkpoint.id)
            
            if restored_data:
                print(f"  ‚úÖ Successfully restored checkpoint: {latest_checkpoint.stage}")
            else:
                print(f"  ‚ùå Failed to restore checkpoint")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Checkpoint demo failed: {e}")
        return None


async def demo_comprehensive_features():
    """Demonstrate all robust features together."""
    print("\n" + "="*80)
    print("üåü DEMO 5: Comprehensive Robustness Features")
    print("="*80)
    
    research_config = ResearchConfig(
        research_topic="Comprehensive Robust AI System with Full Monitoring",
        output_dir="demo_robust_output_comprehensive",
        max_experiments=3
    )
    
    robust_config = RobustConfig(
        research_config=research_config,
        max_retries=3,
        circuit_breaker_enabled=True,
        checkpoint_enabled=True,
        backup_enabled=True,
        stage_timeout_minutes=10.0,
        total_timeout_hours=1.0,
        max_cpu_percent=70.0,
        max_memory_gb=6.0,
        health_check_interval_seconds=15.0,
        metrics_collection_interval_seconds=5.0,
        api_requests_per_minute=100,
        enable_input_validation=True,
        enable_output_sanitization=True,
        min_success_rate=0.8,
        max_error_rate=0.2,
        log_level="INFO"
    )
    
    engine = RobustResearchExecutionEngine(robust_config)
    
    try:
        print("üîÑ Starting comprehensive robust execution...")
        print("   Features enabled:")
        print("   ‚úÖ Error handling and recovery")
        print("   ‚úÖ Circuit breakers and fault tolerance") 
        print("   ‚úÖ Resource monitoring and health checks")
        print("   ‚úÖ Checkpointing and backup systems")
        print("   ‚úÖ Input validation and security")
        print("   ‚úÖ Comprehensive logging and metrics")
        print("   ‚úÖ Automatic cleanup and resource management")
        
        start_time = time.time()
        results = await engine.execute_research_pipeline()
        execution_time = time.time() - start_time
        
        print(f"\nüéâ COMPREHENSIVE EXECUTION COMPLETED!")
        print(f"   Duration: {execution_time:.2f} seconds")
        print(f"   Status: {results['status']}")
        print(f"   Execution ID: {results['execution_id']}")
        
        # Comprehensive metrics summary
        system_metrics = results.get('system_metrics', {})
        stages = results.get('stages', {})
        errors = results.get('errors', [])
        recoveries = results.get('recovery_info', [])
        
        print(f"\nüìä EXECUTION SUMMARY:")
        print(f"   Stages: {len([s for s in stages.values() if s.get('status') == 'completed'])}/{len(stages)} completed")
        print(f"   Errors handled: {len(errors)}")
        print(f"   Recoveries performed: {len(recoveries)}")
        
        if system_metrics:
            health_status = system_metrics.get('health_status', {})
            resource_usage = system_metrics.get('resource_usage', {})
            alerts = system_metrics.get('resource_alerts', [])
            
            print(f"   Final health score: {health_status.get('overall_health_score', 'N/A')}/100")
            print(f"   Resource alerts: {len(alerts)}")
            
            if resource_usage:
                print(f"   Peak CPU: {resource_usage.get('cpu_percent', 'N/A')}%")
                print(f"   Peak memory: {resource_usage.get('memory_percent', 'N/A')}%")
        
        # Show data persistence
        checkpoints = engine.checkpoint_manager.list_checkpoints()
        backups = engine.backup_manager.list_backups()
        
        print(f"\nüíæ DATA PERSISTENCE:")
        print(f"   Checkpoints created: {len(checkpoints)}")
        print(f"   Backups created: {len(backups)}")
        print(f"   Output directory: {robust_config.research_config.output_dir}")
        
        # Validate output files
        output_dir = Path(robust_config.research_config.output_dir)
        if output_dir.exists():
            log_files = list((output_dir / "logs").glob("*.log")) if (output_dir / "logs").exists() else []
            report_files = list(output_dir.glob("*.md"))
            
            print(f"   Log files: {len(log_files)}")
            print(f"   Report files: {len(report_files)}")
        
        print(f"\n‚ú® All robustness features successfully demonstrated!")
        return results
        
    except Exception as e:
        print(f"‚ùå Comprehensive demo failed: {e}")
        return None


async def run_all_demos():
    """Run all demonstration scenarios."""
    print("üöÄ ROBUST RESEARCH EXECUTION ENGINE DEMONSTRATION")
    print("=" * 80)
    print("This demonstration showcases the comprehensive robustness and")
    print("reliability features of the AI Scientist v2 system.")
    print("=" * 80)
    
    if not ROBUST_ENGINE_AVAILABLE:
        print("‚ùå Robust execution engine not available. Please check imports.")
        return
    
    demo_results = {}
    
    try:
        # Demo 1: Basic functionality
        demo_results['basic'] = await demo_basic_robust_execution()
        await asyncio.sleep(2)
        
        # Demo 2: Error handling
        demo_results['error_handling'] = await demo_error_handling_and_recovery()
        await asyncio.sleep(2)
        
        # Demo 3: Resource monitoring
        demo_results['monitoring'] = await demo_resource_monitoring()
        await asyncio.sleep(2)
        
        # Demo 4: Checkpoints and backups
        demo_results['checkpoints'] = await demo_checkpoint_and_backup()
        await asyncio.sleep(2)
        
        # Demo 5: Comprehensive features
        demo_results['comprehensive'] = await demo_comprehensive_features()
        
    except KeyboardInterrupt:
        print("\nüõë Demonstration interrupted by user")
        return demo_results
    except Exception as e:
        print(f"\n‚ùå Demonstration failed: {e}")
        return demo_results
    
    # Final summary
    print("\n" + "="*80)
    print("üèÅ DEMONSTRATION COMPLETE")
    print("="*80)
    
    successful_demos = [name for name, result in demo_results.items() if result is not None]
    failed_demos = [name for name, result in demo_results.items() if result is None]
    
    print(f"Successful demonstrations: {len(successful_demos)}/{len(demo_results)}")
    print(f"‚úÖ Passed: {', '.join(successful_demos)}")
    
    if failed_demos:
        print(f"‚ùå Failed: {', '.join(failed_demos)}")
    
    print(f"\nüìÅ Output directories created:")
    for demo_name in demo_results.keys():
        output_dir = f"demo_robust_output_{demo_name}"
        if Path(output_dir).exists():
            print(f"   - {output_dir}/")
    
    print(f"\nüìù Log file created: demo_robust_execution.log")
    
    print(f"\nüåü The Robust Research Execution Engine has demonstrated:")
    print(f"   ‚úÖ Enterprise-grade reliability and fault tolerance")
    print(f"   ‚úÖ Comprehensive error handling and recovery")
    print(f"   ‚úÖ Real-time resource monitoring and health checks")
    print(f"   ‚úÖ Automatic checkpointing and backup systems")
    print(f"   ‚úÖ Self-healing and adaptive behavior")
    print(f"   ‚úÖ Production-ready monitoring and observability")
    
    return demo_results


if __name__ == "__main__":
    setup_demo_logging()
    
    try:
        results = asyncio.run(run_all_demos())
        print(f"\nüéâ Demonstration completed successfully!")
        sys.exit(0)
    except KeyboardInterrupt:
        print(f"\nüõë Interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\nüí• Demonstration failed: {e}")
        sys.exit(1)