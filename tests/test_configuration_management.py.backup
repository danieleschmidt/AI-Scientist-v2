#!/usr/bin/env python3
"""
Test suite for centralized configuration management system.
Tests the requirements from backlog item: configuration-management (WSJF: 3.5)

Acceptance criteria:
- Create centralized config system
- Move all hardcoded values to config files
- Add environment-specific overrides
- Implement config validation
"""

import unittest
import tempfile
import os
import json
from pathlib import Path
from unittest.mock import patch
import sys

# Optional YAML support for testing
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False
    yaml = None

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ai_scientist.utils.config import (
    ConfigurationManager, 
    get_config, 
    init_config,
    get_api_config,
    get_model_config,
    get_timeout_config,
    get_temp_config
)


class TestConfigurationManagement(unittest.TestCase):
    """Test centralized configuration management functionality."""
    
    def setUp(self):
        """Set up test fixtures."""
        # Clear any existing global config
        import ai_scientist.utils.config
        ai_scientist.utils.config._config_manager = None
        
        # Create temporary config files for testing
        self.temp_dir = tempfile.mkdtemp()
        self.yaml_config_path = Path(self.temp_dir) / "test_config.yaml"
        self.json_config_path = Path(self.temp_dir) / "test_config.json"
        
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
        
        # Clear environment variables
        for key in list(os.environ.keys()):
            if key.startswith('AI_SCIENTIST_'):
                del os.environ[key]
    
    def test_configuration_manager_initialization(self):
        """Test that ConfigurationManager initializes with default values."""
        config = ConfigurationManager()
        
        # Test that some key default values are loaded
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://api.deepseek.com")
        self.assertEqual(config.get("MAX_LLM_TOKENS"), 4096)
        self.assertEqual(config.get("LATEX_COMPILE_TIMEOUT"), 30)
        self.assertEqual(config.get("DEFAULT_MODEL_SEED"), 0)
        
        # Test that available models list is loaded
        llm_models = config.get("AVAILABLE_LLM_MODELS")
        self.assertIsInstance(llm_models, list)
        self.assertIn("claude-3-5-sonnet-20240620", llm_models)
        self.assertIn("gpt-4o-2024-11-20", llm_models)
    
    @unittest.skipUnless(HAS_YAML, "PyYAML not available")
    def test_yaml_config_file_loading(self):
        """Test loading configuration from YAML file."""
        # Create test YAML config
        test_config = {
            "API_DEEPSEEK_BASE_URL": "https://custom.deepseek.com",
            "MAX_LLM_TOKENS": 8192,
            "TEMP_REPORT": 0.8,
            "AVAILABLE_LLM_MODELS": ["custom-model-1", "custom-model-2"]
        }
        
        with open(self.yaml_config_path, 'w') as f:
            yaml.dump(test_config, f)
        
        config = ConfigurationManager(self.yaml_config_path)
        
        # Verify values were loaded from file
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://custom.deepseek.com")
        self.assertEqual(config.get("MAX_LLM_TOKENS"), 8192)
        self.assertEqual(config.get("TEMP_REPORT"), 0.8)
        self.assertEqual(config.get("AVAILABLE_LLM_MODELS"), ["custom-model-1", "custom-model-2"])
        
        # Verify unspecified values use defaults
        self.assertEqual(config.get("MAX_VLM_TOKENS"), 4096)  # Default value
    
    def test_json_config_file_loading(self):
        """Test loading configuration from JSON file."""
        # Create test JSON config
        test_config = {
            "API_OPENROUTER_BASE_URL": "https://custom.openrouter.com",
            "INTERPRETER_TIMEOUT": 7200,
            "NUM_WORKERS": 8
        }
        
        with open(self.json_config_path, 'w') as f:
            json.dump(test_config, f)
        
        config = ConfigurationManager(self.json_config_path)
        
        # Verify values were loaded from file
        self.assertEqual(config.get("API_OPENROUTER_BASE_URL"), "https://custom.openrouter.com")
        self.assertEqual(config.get("INTERPRETER_TIMEOUT"), 7200)
        self.assertEqual(config.get("NUM_WORKERS"), 8)
    
    @unittest.skipUnless(HAS_YAML, "PyYAML not available")
    def test_environment_variable_overrides(self):
        """Test that environment variables override config file values.""
        # Set up environment variables
        os.environ["AI_SCIENTIST_API_DEEPSEEK_BASE_URL"] = "https://env.deepseek.com"
        os.environ["AI_SCIENTIST_MAX_LLM_TOKENS"] = "16384"
        os.environ["AI_SCIENTIST_TEMP_FEEDBACK"] = "0.3"
        os.environ["AI_SCIENTIST_AVAILABLE_LLM_MODELS"] = "env-model-1,env-model-2,env-model-3"
        
        # Create config file with different values
        test_config = {
            "API_DEEPSEEK_BASE_URL": "https://file.deepseek.com",
            "MAX_LLM_TOKENS": 2048,
            "TEMP_FEEDBACK": 0.7
        }
        
        with open(self.yaml_config_path, 'w') as f:
            yaml.dump(test_config, f)
        
        config = ConfigurationManager(self.yaml_config_path)
        
        # Verify environment variables take precedence
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://env.deepseek.com")
        self.assertEqual(config.get("MAX_LLM_TOKENS"), 16384)
        self.assertEqual(config.get("TEMP_FEEDBACK"), 0.3)
        self.assertEqual(config.get("AVAILABLE_LLM_MODELS"), ["env-model-1", "env-model-2", "env-model-3"])
    
    def test_configuration_validation(self):
        """Test configuration validation against schema."""
        config = ConfigurationManager()
        
        # Test valid configuration doesn't raise errors
        config.set("MAX_LLM_TOKENS", 4096)
        config.set("TEMP_REPORT", 1.0)
        
        # Test that we can set values (validation warnings are logged, not raised)
        config.set("MAX_LLM_TOKENS", -1)  # Invalid, but doesn't raise
        config.set("TEMP_REPORT", 3.0)    # Invalid, but doesn't raise
        
        # Values should still be set (validation is advisory)
        self.assertEqual(config.get("MAX_LLM_TOKENS"), -1)
        self.assertEqual(config.get("TEMP_REPORT"), 3.0)
    
    def test_global_config_functions(self):
        """Test global configuration access functions."""
        # Initialize global config
        config = init_config()
        
        # Test get_config returns the same instance
        self.assertIs(get_config(), config)
        
        # Test convenience functions
        api_url = get_api_config("deepseek")
        self.assertEqual(api_url, "https://api.deepseek.com")
        
        llm_models = get_model_config("llm")
        self.assertIsInstance(llm_models, list)
        self.assertIn("claude-3-5-sonnet-20240620", llm_models)
        
        timeout = get_timeout_config("latex_compile")
        self.assertEqual(timeout, 30)
        
        temp = get_temp_config("report")
        self.assertEqual(temp, 1.0)
    
    @unittest.skipUnless(HAS_YAML, "PyYAML not available")
    def test_config_export(self):
        """Test configuration export functionality."""
        config = ConfigurationManager()
        
        # Export to YAML
        yaml_export_path = Path(self.temp_dir) / "exported_config.yaml"
        config.export_config(yaml_export_path, format='yaml')
        
        self.assertTrue(yaml_export_path.exists())
        
        # Verify exported YAML can be loaded
        with open(yaml_export_path, 'r') as f:
            exported_config = yaml.safe_load(f)
        
        self.assertIn("API_DEEPSEEK_BASE_URL", exported_config)
        self.assertIn("MAX_LLM_TOKENS", exported_config)
        
        # Export to JSON
        json_export_path = Path(self.temp_dir) / "exported_config.json"
        config.export_config(json_export_path, format='json')
        
        self.assertTrue(json_export_path.exists())
        
        # Verify exported JSON can be loaded
        with open(json_export_path, 'r') as f:
            exported_config = json.load(f)
        
        self.assertIn("API_DEEPSEEK_BASE_URL", exported_config)
        self.assertIn("MAX_LLM_TOKENS", exported_config)
    
    def test_nonexistent_config_file(self):
        """Test behavior when config file doesn't exist."""
        nonexistent_path = Path(self.temp_dir) / "nonexistent.yaml"
        
        # Should not raise an error, just use defaults
        config = ConfigurationManager(nonexistent_path)
        
        # Should have default values
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://api.deepseek.com")
        self.assertEqual(config.get("MAX_LLM_TOKENS"), 4096)
    
    def test_invalid_config_file_format(self):
        """Test behavior with invalid config file."""
        invalid_config_path = Path(self.temp_dir) / "invalid.yaml"
        
        # Create invalid YAML file
        with open(invalid_config_path, 'w') as f:
            f.write("invalid: yaml: content: [unclosed")
        
        # Should not raise an error, just use defaults
        config = ConfigurationManager(invalid_config_path)
        
        # Should have default values despite invalid file
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://api.deepseek.com")
    
    @unittest.skipUnless(HAS_YAML, "PyYAML not available")
    def test_unknown_config_keys(self):
        """Test handling of unknown configuration keys.""
        test_config = {
            "API_DEEPSEEK_BASE_URL": "https://custom.deepseek.com",
            "UNKNOWN_CONFIG_KEY": "unknown_value",
            "ANOTHER_UNKNOWN_KEY": 12345
        }
        
        with open(self.yaml_config_path, 'w') as f:
            yaml.dump(test_config, f)
        
        config = ConfigurationManager(self.yaml_config_path)
        
        # Known keys should be loaded
        self.assertEqual(config.get("API_DEEPSEEK_BASE_URL"), "https://custom.deepseek.com")
        
        # Unknown keys should be ignored (not loaded)
        self.assertIsNone(config.get("UNKNOWN_CONFIG_KEY"))
        self.assertIsNone(config.get("ANOTHER_UNKNOWN_KEY"))
    
    def test_get_all_configuration(self):
        """Test getting all configuration values."""
        config = ConfigurationManager()
        
        all_config = config.get_all()
        
        # Should be a dictionary with all schema keys
        self.assertIsInstance(all_config, dict)
        self.assertIn("API_DEEPSEEK_BASE_URL", all_config)
        self.assertIn("MAX_LLM_TOKENS", all_config)
        self.assertIn("AVAILABLE_LLM_MODELS", all_config)
        
        # Should have at least all the schema keys
        from ai_scientist.utils.config import ConfigurationManager
        temp_config = ConfigurationManager()
        schema_keys = set(temp_config._schema.keys())
        config_keys = set(all_config.keys())
        
        self.assertTrue(schema_keys.issubset(config_keys))


class TestConfigurationIntegration(unittest.TestCase):
    """Test integration of configuration system with existing code patterns."""
    
    def setUp(self):
        """Set up test fixtures."""
        import ai_scientist.utils.config
        ai_scientist.utils.config._config_manager = None
    
    def test_api_url_configuration(self):
        """Test that API URLs can be configured centrally."""
        config = get_config()
        
        # Test different API providers
        deepseek_url = get_api_config("deepseek")
        self.assertEqual(deepseek_url, "https://api.deepseek.com")
        
        openrouter_url = get_api_config("openrouter")
        self.assertEqual(openrouter_url, "https://openrouter.ai/api/v1")
        
        # Test case insensitivity
        gemini_url = get_api_config("GEMINI")
        self.assertEqual(gemini_url, "https://generativelanguage.googleapis.com/v1beta/openai/")
    
    def test_model_configuration_access(self):
        """Test model configuration access patterns."""
        # Test LLM models
        llm_models = get_model_config("llm")
        self.assertIsInstance(llm_models, list)
        self.assertGreater(len(llm_models), 0)
        
        # Test VLM models
        vlm_models = get_model_config("vlm")
        self.assertIsInstance(vlm_models, list)
        self.assertGreater(len(vlm_models), 0)
        
        # Test default models
        default_writeup = get_model_config("writeup")
        self.assertIsInstance(default_writeup, str)
        self.assertGreater(len(default_writeup), 0)
    
    def test_timeout_configuration_access(self):
        """Test timeout configuration access patterns."""
        # Test various timeout configurations
        latex_timeout = get_timeout_config("latex_compile")
        self.assertIsInstance(latex_timeout, int)
        self.assertGreater(latex_timeout, 0)
        
        pdf_timeout = get_timeout_config("pdf_detection")
        self.assertIsInstance(pdf_timeout, int)
        self.assertGreater(pdf_timeout, 0)
        
        # Test case insensitivity
        interp_timeout = get_timeout_config("INTERPRETER")
        self.assertIsInstance(interp_timeout, int)
        self.assertGreater(interp_timeout, 0)
    
    def test_temperature_configuration_access(self):
        """Test temperature configuration access patterns."""
        # Test various temperature configurations
        report_temp = get_temp_config("report")
        self.assertIsInstance(report_temp, float)
        self.assertGreaterEqual(report_temp, 0.0)
        self.assertLessEqual(report_temp, 2.0)
        
        code_temp = get_temp_config("code")
        self.assertIsInstance(code_temp, float)
        
        # Test case insensitivity
        feedback_temp = get_temp_config("FEEDBACK")
        self.assertIsInstance(feedback_temp, float)


if __name__ == '__main__':
    unittest.main()